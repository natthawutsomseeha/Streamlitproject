import joblib
from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
import pandas as pd

# à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
file_path = "cardio_train.csv"  # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸¡à¸µà¹„à¸Ÿà¸¥à¹Œà¸™à¸µà¹‰à¸­à¸¢à¸¹à¹ˆ
df = pd.read_csv(file_path, sep=";")

# à¸—à¸³à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
df.drop(columns=["id"], inplace=True)
df["age"] = (df["age"] / 365).astype(int)
df_cleaned = df[
    (df["height"] >= 100) & (df["height"] <= 250) &
    (df["weight"] >= 30) & (df["weight"] <= 200) &
    (df["ap_hi"] >= 50) & (df["ap_hi"] <= 250) &
    (df["ap_lo"] >= 30) & (df["ap_lo"] <= 200)
]

# à¹à¸¢à¸ Features à¹à¸¥à¸° Target
X = df_cleaned.drop(columns=["cardio"])
y = df_cleaned["cardio"]

# à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Train/Test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸¡à¹€à¸”à¸¥ Voting Classifier
models = [
    ("LoR", LogisticRegression(max_iter=1000, random_state=42)),
    ("kNN", KNeighborsClassifier(n_neighbors=5)),
    ("DT", DecisionTreeClassifier(random_state=42)),
    ("GB", GradientBoostingClassifier(random_state=42)),
    ("RF", RandomForestClassifier(n_estimators=100, random_state=42)),
    ("Adaboost", AdaBoostClassifier(random_state=42))
]

voting_clf = VotingClassifier(estimators=models, voting="hard")
voting_clf.fit(X_train, y_train)

# à¸šà¸±à¸™à¸—à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥
joblib.dump(voting_clf, "voting_classifier.pkl")
print("à¸šà¸±à¸™à¸—à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥à¸ªà¸³à¹€à¸£à¹‡à¸ˆ! ðŸŽ‰")
